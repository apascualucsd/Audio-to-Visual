# Audio-to-Visual

Developed an innovative system that collects FFT data from a microphone, incorporating advanced signal filtering and amplification techniques. Leveraged a neural network to analyze and predict color representations based on the musical context, enabling the conversion of auditory information into dynamic visualizations. Created an adaptive spectrogram that tracks amplitude and frequency variations in real-time, providing a vivid and responsive visual representation of the audio data

## My Role:

Engineered an advanced algorithm to transform audio data captured from a microphone into precise frequency and amplitude components, which are then seamlessly converted into RGB tuples for sophisticated data visualization and analysis.
